---
description: Story Flow: Validation rules and debugging checkpoints
globs: 
---
# Story Flow Debug Guide

<story_testing>
When running story generation tests: 
1. ALWAYS run the test file directly with Python:
   `source .venv/bin/activate && python tests/test_story_generation.py`
2. DO NOT use pytest as it will hide the debug output
3. This ensures you can see all prompts and LLM responses in the output
</story_testing>

## CRITICAL: Narrative Context Checks
Before anything else, verify these essential context points:

### 1. Past Chapter Narrative Preservation
Verify in _build_base_prompt:
- ✓ ALL previous chapters must be APPENDED (not overwritten)
- ✓ Format: Each chapter prefixed with "Chapter {number}:"
- ✓ Chapters separated by "---"
- Debug: print(base_prompt) should show complete history

### 2. Previous Lesson Context
If previous chapter was LESSON type:
- ✓ Question asked: state.chapters[-1].response.question
- ✓ User's answer: state.chapters[-1].response.chosen_answer
- ✓ Correctness: state.chapters[-1].response.is_correct
- Debug: Verify these appear in prompt before new content

### 3. Previous Choice Context
If previous chapter was STORY type:
- ✓ ONLY chosen option: state.chapters[-1].response.choice_text
- ✓ NO other choices should be included
- ✓ Choice consequences must be reflected
- Debug: Verify only selected choice appears in prompt

## Quick Debug Checklist
Before deep diving, verify these common failure points:
1. Narrative Flow:
   - Run: print(state.chapters[-1].content) → Should show last chapter
   - Check: base_prompt contains all chapter content
   - Verify: "---" separators between chapters

2. State Consistency:
   - Expected: current_chapter_number == len(state.chapters) + 1
   - Expected: remaining_chapters == story_length - current_chapter_number
   - Expected: response type matches chapter_type

3. Response Chain:
   - Verify: state.chapters[-1].response exists
   - Check: previous_lessons contains all lesson history
   - Confirm: consequences_guidance reflects last response

## Core Function Debug Points

### build_user_prompt
Input validation:
- state: Must contain complete chapter history
- lesson_question: Must be formatted if LESSON type
- previous_lessons: Must include all past lessons

Common failures:
- Missing narrative: Check _build_base_prompt return
- Incorrect phase: Verify story_phase calculation
- Response mismatch: Check chapter_type alignment

### _build_base_prompt
Critical checks:
- Chapter history construction complete
- Phase calculation matches position
- Progress metrics accurate

Failure indicators:
- Incomplete history: Check state.chapters iteration
- Wrong phase: Verify remaining_chapters calc
- Missing separators: Check chapter formatting

### _build_chapter_prompt
Validation points:
- Previous content flows into new
- Format matches chapter_type
- Consequences reflected in prompt

Common issues:
- Narrative break: Check content integration
- Format mismatch: Verify type-specific formatting
- Missing context: Check previous response processing

## Debugging By Symptom

### 1. Broken Narrative Flow
Symptoms:
- Current chapter doesn't reference previous events
- Missing character development
- Inconsistent plot points

Debug steps:
1. Check state.chapters completeness
2. Verify _build_base_prompt output
3. Trace narrative through prompt construction

### 2. Incorrect Lesson Processing
Symptoms:
- Wrong answer validation
- Missing previous lesson context
- Incorrect progress tracking

Debug steps:
1. Verify LessonResponse structure
2. Check correct_lesson_answers count
3. Trace lesson history formatting

### 3. Choice Consequence Failures
Symptoms:
- Choices don't reflect previous decisions
- Character development breaks
- Plot inconsistencies

Debug steps:
1. Verify StoryResponse integration
2. Check consequences_guidance generation
3. Trace choice history in prompts

### 4. State Transition Issues
Symptoms:
- Wrong chapter numbers
- Phase miscalculation
- Response type mismatches

Debug steps:
1. Verify chapter progression logic
2. Check phase calculation
3. Validate response type matching

## Type Validation Points
Key classes to check when debugging:
- AdventureState: Holds complete story state
- ChapterData: Contains chapter content and response
- LessonResponse: Tracks lesson outcomes
- StoryResponse: Records choice history

Note: Reference models.py for complete type definitions

## Debug Environment Setup
For effective debugging:
1. Enable debug logging in chapter_manager
2. Monitor state transitions between chapters
3. Validate prompt construction at each step
4. Check response processing flow

